This milestone is being led by Roseline Polle. It should take approximately four hours to complete. 

This week, we start looking at some technical aspects of bias and fairness in AI: given a machine learning problem, how can we assess and measure bias? What are the different types of bias and where do they come from? The session is divided in two main parts:


**Part 1: Theory** <br>
_Material: 4 videos (with slide decks available) + supporting "cheatsheet" notebook_
- Theory 1: Real-life examples of bias in algorithms
- Theory 2: Type and sources of Bias
- Theory 3: Quantification of Bias: different definitions of fairness and associate
- Theory 4: How to choose a metric

**Part 2: Practice** <br>
_Material: 4 notebooks_ 

We look at a specific Supervised Learning problem where a company uses an algorithm in their hiring process to decide which candidates go to the next round. Candidates are labelled either "pass" (0) or "fail" (1).  This part contains 4 separate notebooks that are linked below. They are:
- Notebook 1: Explore the given data: find label distribution per group and look for proxies
- Notebook 2: Measure model bias "by hand" using the following metrics: Statistical Parity, Disparate Impact, Equal Opportunity Difference
- Notebook 3: Measure model bias using aif360
- Notebook 4: Use bootstrap sampling to get a confidence interval for each metric


**Practice Instructions:**<br>
You can chose to download the notebooks on your machine and use them with jupyter, or open them directly through Google Colab. 
If the latter:
- Make sure you copy them in your own Google Drive as the original files are not editable.
- When clicking on a notebook link, right click and open in a new tab as otherwise it will leave the Moodle page by default.

If you use the notebooks locally:
- The data can be downloaded here: https://docs.google.com/uc?export=download&id=1-Wd1evAoDs4YsjRLfC-ifarmQL-Ozg3R. 
- Make sure to save the data in the same folder as the notebooks. 
