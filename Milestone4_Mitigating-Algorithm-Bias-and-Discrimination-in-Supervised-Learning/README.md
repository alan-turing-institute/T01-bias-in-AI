This week's session is being led by Catherine Inness. It should take approximately four hours to complete. 

This week's content introduces mitigation strategies to improve fairness of supervised learning models. By the end of this week, you will be able to select, implement and evaluate example methods from the three families of technical intervention: pre-processing, in-processing and post-processing.

**Part 1: Theory.** <br>
*Material: 1 video (with slide deck available) covering:*
1. What are we mitigating for?
2. What intervention techniques exist to mitigate
3. Selecting a target fairness measure to mitigate
4. Explanation of an example method for pre-processing, in-processing and post-processing
5. Closing thoughts on the effectiveness of these methods, and other considerations to be aware of

**Part 2: Practice.** <br>
*Material: 3 notebooks* <br>
We look at the same Supervised Learning problem as in week 3: a company uses an algorithm in their hiring process to decide which candidates go to the next round. Candidates are labelled either "pass" (0) or "fail" (1).  This part contains 3 separate notebooks that are linked below. They are:
- Notebook 1: Algorithm Pre-processing example: Reweighing (Kamiran and Calders 2012)
- Notebook 2: Algorithm In-processing example: Reductions (Argarwal et al 2018)
- Notebook 3: Algorithm Post-processing example: Equalised Odds Post-processing (Hardt et al 2016)

**Practice Instructions:** <br>
You can choose to download the notebooks on your machine and use them with jupyter, or open them directly through Google Colab. 

If the latter:
- Make sure you copy them in your own Google Drive as the original files are not editable.

If you use the notebooks locally:
- The data can be downloaded here: TBC
- Make sure to save the data in the same folder as the notebooks. 
